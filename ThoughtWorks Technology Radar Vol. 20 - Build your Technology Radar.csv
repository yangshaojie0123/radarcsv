name,ring,quadrant,isNew,description
Jupyter,adopt,tools,TRUE,"<p>Over the past couple of years, we've noticed a steady rise in the popularity of analytics notebooks. These are Mathematica-inspired applications that combine text, visualization and code in a living, computational document. <strong><a href=""http://jupyter.org/"">Jupyter</a></strong> Notebooks are widely used by our teams for prototyping and exploration in analytics and machine learning. We've moved Jupyter to Adopt for this issue of the Radar to reflect that it has emerged as the current default for Python notebooks. However, we caution to use <a href=""/radar/techniques/productionizing-jupyter-notebooks"">Jupyter Notebooks in production</a>.</p>"
TestCafe,trial,tools,TRUE,"<p>We have good experience using ""post-Selenium"" web UI testing tools such as <a href=""/radar/tools/cypress"">Cypress</a>, <strong><a href=""https://github.com/DevExpress/testcafe"">TestCafe</a></strong> and <a href=""/radar/languages-and-frameworks/puppeteer"">Puppeteer</a>. TestCafe lets you write tests in JavaScript or <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a> and runs in-browser tests. TestCafe has several useful features that include out-of-the-box parallel execution and HTTP request mocking. TestCafe uses an asynchronous execution model with no explicit wait times, which results in much more stable test suites. Its selector API makes it easier to implement <a href=""https://martinfowler.com/bliki/PageObject.html"">PageObject</a> patterns. TestCafe recently released version 1.0.<em>x</em>, which improved stability and functionality.</p>"
Honeycomb,assess,tools,TRUE,"<p><strong><a href=""https://www.honeycomb.io/"">Honeycomb</a></strong> is an observability tool that ingests rich data from production systems and makes it manageable through dynamic sampling. Developers can log large amounts of rich events and decide later how to slice and correlate them. This interactive approach is useful when working with today's large distributed systems because we've passed the point where we can reasonably anticipate which questions we might want to ask of production systems.</p>"
Kubernetes Operators,assess,tools,TRUE,"<p>We're excited about the impact <a href=""/radar/platforms/kubernetes"">Kubernetes</a> has had on our industry but also concerned about the operational complexity that comes with it. Keeping a Kubernetes cluster up and running and then managing packages deployed on it requires special skills and time. Operational processes such as upgrades, migrations, backups, among others, can be a full-time job. We think that <strong><a href=""https://coreos.com/operators/"">Kubernetes Operators</a></strong> will play a key role in reducing this complexity. The framework provides a standard mechanism to describe automated operational processes for packages running in a Kubernetes cluster. Although Operators were spearheaded and promoted by RedHat, several community-developed Operators for common open-source packages such as <a href=""/radar/tools/jaeger"">Jaeger</a>, <a href=""/radar/platforms/mongodb"">MongoDB</a> and <a href=""/radar/platforms/redis"">Redis</a> have begun to emerge.</p>"
Apollo,adopt,language-and-frameworks,TRUE,"<p>Our teams report that <strong><a href=""http://www.apollographql.com/client"">Apollo</a></strong> has become the library of choice when building a <a href=""/radar/languages-and-frameworks/react-js"">React</a> application that uses GraphQL to access data from a <a href=""/radar/techniques/bff-backend-for-frontends"">back-end</a> service. Although the Apollo project also provides a server framework and a GraphQL gateway, the Apollo client gets our attention because it simplifies the problem of binding UI components to data served by any GraphQL backend. Put simply, this means less code needs to be written than using REST backends and redux.</p>"
fastai,assess,language-and-frameworks,TRUE,"<p><strong><a href=""https://docs.fast.ai/"">fastai</a></strong> is an open-source Python library that simplifies training fast and accurate neural nets. It is built on top of <a href=""/radar/languages-and-frameworks/pytorch"">PyTorch</a> and has become a popular tool for our data scientists. fastai simplifies painful aspects of model training such as preprocessing and loading data down to a few lines of code. It's built on deep learning best practices and has out-of-the-box support for computer vision, natural language processing (NLP) and more. The founders' motivation has been to create an easy-to-use library for deep learning and an improved successor to <a href=""/radar/languages-and-frameworks/keras"">Keras</a>. <a href=""/radar/platforms/google-cloud-platform"">GCP</a>, <a href=""/radar/platforms/aws"">AWS</a> and <a href=""/radar/platforms/azure"">Azure</a> all have already included fastai in their machine images. The creators of fastai, acknowledging the speed and safety limitations of Python, have announced <a href=""https://www.fast.ai/2019/03/06/fastai-swift/"">embracing Swift</a> as an alternative language for deep learning. We'll be closely watching this space.</p>"
AWS Fargate,trial,platforms,TRUE,"<p><strong><a href=""http://aws.amazon.com/fargate/"">AWS Fargate</a></strong>, the docker-as-a-service option on <a href=""/radar/platforms/aws"">AWS</a>, is now widely available across regions. It's a great solution for situations in which teams want to run Docker containers, because <a href=""/radar/platforms/aws-lambda"">AWS Lambda</a> functions aren't powerful enough, without having to manage EC2 instances or Kubernetes clusters. Our teams report generally positive experiences with Fargate; however, the convenience of this managed service can come at a cost, in financial terms.</p>"
Kafka Streams,trial,platforms,TRUE,"<p><strong><a href=""https://kafka.apache.org/documentation/streams/"">Kafka Streams</a></strong> is a lightweight library to build streaming applications. It supports basic streaming APIs such as join, filter, map and aggregate as well as local storage for common use cases such as windowing and sessions. Unlike other stream-processing platforms such as <a href=""/radar/platforms/apache-spark"">Apache Spark</a> and <a href=""https://doc.akka.io/docs/akka-stream-kafka/current/home.html"">Alpakka Kafka</a>, Kafka Streams has been a good fit for scenarios that don't require large-scale distribution and parallel processing; hence we could get away without yet another piece of infrastructure such as cluster schedulers. Naturally, Kafka Streams has been a good choice when operating in the Kafka ecosystem. Kafka Streams is particularly useful when we have to process data strictly in order and exactly once. One particular use case of Kafka Streams is to build a <a href=""https://en.wikipedia.org/wiki/Change_data_capture#Event_Programming"">change data capture (CDC)</a> platform.</p>"
Continuous delivery for machine learning (CD4ML) models,trial,techniques,TRUE,"<p><strong>Continuous delivery for machine learning (CD4ML) models</strong> apply continuous delivery practices to developing machine learning models so that they are always ready for production. This technique addresses two main problems of traditional machine learning model development: long cycle time between training models and deploying them to production, which often includes manually converting the model to production-ready code; and using production models that had been trained with stale data.</p>

<p>A continuous delivery pipeline of a machine learning model has two triggers: (1) changes to the structure of the model and (2) changes to the training and test data sets. For this to work we need to both version <a href=""/radar/techniques/versioning-data-for-reproducible-analytics"">the data sets</a> and the model's source code. The pipeline often includes steps such as testing the model against the test data set, applying automatic conversion of the model (if necessary) with tools such as <a href=""https://www.h2o.ai/"">H2O</a>, and deploying the model to production to deliver value.</p>"
Transfer learning for NLP,assess,techniques,TRUE,"<p>Transfer learning has been quite effective within the field of computer vision, speeding the time to train a model by reusing existing models. Those of us who work in machine learning are excited that the same techniques can be applied to natural language processing (NLP) with the publication of <a href=""https://arxiv.org/abs/1801.06146"">ULMFiT</a> and open source pretrained models and code examples. We think <strong>transfer learning for NLP</strong> will significantly reduce the effort to create systems dealing with text classification.</p>"
Wardley mapping,assess,techniques,TRUE,"<p>We're usually wary of covering diagrammatic techniques, but <strong><a href=""https://medium.com/wardleymaps"">Wardley mapping</a></strong> is an interesting approach to start conversations around the evolution of an organization's software estate. At their simplest, they're used to visualize the value chains that exist within an organization, starting with customers' needs and progressively plotting the different capabilities and systems used to deliver on those needs along with the evolution of those capabilities and systems. The value of this technique is the process of collaborating to create the maps rather than the artefact itself. We recommend getting the right people in the room to produce them, and then treat them as living, evolving things rather than a complete artefact.</p>"
Productionizing Jupyter Notebooks,hold,techniques,TRUE,"<p><a href=""/radar/tools/jupyter"">Jupyter Notebooks</a> have gained in popularity among data scientists who use them for exploratory analyses, early-stage development and knowledge sharing. This rise in popularity has led to the trend of <strong>productionizing Jupyter Notebooks</strong>, by providing the tools and support to execute them at scale. Although we wouldn't want to discourage anyone from using their tools of choice, we don't recommend using Jupyter Notebooks for building scalable, maintainable and long-lived production code â€?they lack effective version control, error handling, modularity and extensibility among other basic capabilities required for building scalable, production-ready code. Instead, we encourage developers and data scientists to work together to find solutions that empower data scientists to build production-ready machine learning models using <a href=""/radar/techniques/continuous-delivery-for-machine-learning-cd4ml-models"">continuous delivery</a> practices with the right programming frameworks. We caution against productionization of Jupyter Notebooks to overcome inefficiencies in continuous delivery pipelines for machine learning, or inadequate automated testing.</p>"
Puncturing encapsulation with change data capture,hold,techniques,TRUE,"<p><a href=""https://en.wikipedia.org/wiki/Change_data_capture"">Change data capture</a> (CDC) is a very powerful technique for pulling database changes out of a system and performing some actions on that data. One of the most popular ways of doing this is to use the database's transaction log to identify changes and then publish those changes directly onto an event bus that can be consumed by other services. This works very well for use cases such as <a href=""https://martinfowler.com/articles/break-monolith-into-microservices.html"">breaking monoliths into microservices</a> but when used for first-class integration between microservices, this leads to puncturing encapsulation and leaking the source service's data layer into the event contract. We've talked about <a href=""/radar/techniques/domain-scoped-events"">domain scoped events</a> and other techniques that emphasize the importance of having our events model our domain properly. We're seeing some projects use CDC for publishing row-level change events and directly consuming these events in other services. This <strong>puncturing of encapsulation with change data capture</strong> can be a slippery slope leading to fragile integrations and we would like to call this out with this blip.</p>"
Release train,hold,techniques,TRUE,"<p>We've seen organizations successfully move from very infrequent releases to a higher cadence by using the <strong>release train</strong> concept. The release train is a technique for coordinating releases across multiple teams or components that have runtime dependencies. All releases happen on a fixed and reliable schedule regardless of whether all expected features are ready (the train doesn't wait for you â€?if you miss it you wait for the next one). Although we wholeheartedly endorse discipline around regularly releasing and demoing working software, we've experienced serious drawbacks with the approach over the medium to long term as it reinforces temporal coupling around sequencing of changes and can degrade quality as teams rush to complete features. We prefer to focus on the architectural and organizational approaches necessary to support independent releases. Although the train can be a useful forcing function for speeding up slower teams, we've also seen it as imposing an upper limit on how quickly faster-moving teams can move. We believe that it is a technique that should be approached with a good degree of caution, if at all.</p>"
